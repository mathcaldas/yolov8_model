{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diurnas - resplit treino/validacao\n",
        "Notebook para recombinar e dividir o dataset em treino/validacao com proporcoes editaveis.\n",
        "- Usa labels vazios como BACKGROUND (imagem sem objetos).\n",
        "- Gera estrutura YOLO em OUTPUT_ROOT/train|valid/{images,labels}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6f5b21f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "import shutil\n",
        "import hashlib\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# ==== CONFIG ====\n",
        "CWD = Path.cwd()\n",
        "PROJECT_ROOT = CWD.parent if CWD.name.lower() == 'notebooks' else CWD\n",
        "\n",
        "SOURCE_ROOT = PROJECT_ROOT / 'data' / 'diurno'  # ou PROJECT_ROOT / 'dataset' / 'Diurnas'\n",
        "OUTPUT_ROOT = PROJECT_ROOT / 'dataset' / 'Diurnas_resplit_v1'\n",
        "VAL_RATIO = 0.2  # mude aqui (ex: 0.1, 0.2, 0.3)\n",
        "SEED = 42\n",
        "\n",
        "SPLIT_STRATEGY = 'primary_label'  # 'primary_label' ou 'multilabel_greedy'\n",
        "COPY_MODE = 'copy'  # 'copy' ou 'move'\n",
        "DRY_RUN = False  # True = nao copia/move arquivos\n",
        "\n",
        "WRITE_DATA_YAML = True\n",
        "CLASS_NAMES = ['N1', 'N2', 'N3']  # BACKGROUND nao entra aqui\n",
        "\n",
        "ALLOW_RENAME_ON_CONFLICT = False  # True para renomear se houver nomes repetidos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8582f772",
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_EXTS = ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.webp']\n",
        "\n",
        "def find_image_for_label(label_path: Path):\n",
        "    images_dir = label_path.parent.parent / 'images'\n",
        "    if not images_dir.exists():\n",
        "        return None\n",
        "    for ext in IMG_EXTS:\n",
        "        candidate = images_dir / f'{label_path.stem}{ext}'\n",
        "        if candidate.exists():\n",
        "            return candidate\n",
        "    matches = list(images_dir.glob(label_path.stem + '.*'))\n",
        "    return matches[0] if matches else None\n",
        "\n",
        "def read_label_info(label_path: Path):\n",
        "    text = label_path.read_text(encoding='utf-8', errors='ignore').strip()\n",
        "    if not text:\n",
        "        return set(), Counter()\n",
        "    counts = Counter()\n",
        "    for line in text.splitlines():\n",
        "        parts = line.strip().split()\n",
        "        if not parts:\n",
        "            continue\n",
        "        try:\n",
        "            cls = int(float(parts[0]))\n",
        "        except ValueError:\n",
        "            continue\n",
        "        counts[cls] += 1\n",
        "    return set(counts.keys()), counts\n",
        "\n",
        "def primary_label(counts: Counter):\n",
        "    if not counts:\n",
        "        return 'BACKGROUND'\n",
        "    return sorted(counts.items(), key=lambda kv: (-kv[1], kv[0]))[0][0]\n",
        "\n",
        "def collect_samples(source_root: Path):\n",
        "    label_files = list(source_root.rglob('labels/*.txt'))\n",
        "    samples = []\n",
        "    missing_images = []\n",
        "    for label_path in label_files:\n",
        "        image_path = find_image_for_label(label_path)\n",
        "        if image_path is None:\n",
        "            missing_images.append(label_path)\n",
        "            continue\n",
        "        labels, counts = read_label_info(label_path)\n",
        "        samples.append({\n",
        "            'image_path': image_path,\n",
        "            'label_path': label_path,\n",
        "            'labels': labels,\n",
        "            'label_counts': counts,\n",
        "            'primary': primary_label(counts),\n",
        "        })\n",
        "    return samples, missing_images\n",
        "\n",
        "def find_name_conflicts(samples):\n",
        "    name_map = defaultdict(list)\n",
        "    for s in samples:\n",
        "        name_map[s['image_path'].name].append(s)\n",
        "    return {name: items for name, items in name_map.items() if len(items) > 1}\n",
        "\n",
        "def make_unique_name(path: Path):\n",
        "    h = hashlib.md5(str(path).encode('utf-8')).hexdigest()[:8]\n",
        "    return f'{path.stem}__{h}{path.suffix}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9bd04160",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 1788\n",
            "Missing images for labels: 0\n",
            "Filename conflicts: 0\n"
          ]
        }
      ],
      "source": [
        "samples, missing_images = collect_samples(SOURCE_ROOT)\n",
        "print(f'Total samples: {len(samples)}')\n",
        "print(f'Missing images for labels: {len(missing_images)}')\n",
        "if missing_images[:5]:\n",
        "    print('Example missing labels:')\n",
        "    for p in missing_images[:5]:\n",
        "        print('  ', p)\n",
        "\n",
        "conflicts = find_name_conflicts(samples)\n",
        "print(f'Filename conflicts: {len(conflicts)}')\n",
        "if conflicts and not ALLOW_RENAME_ON_CONFLICT:\n",
        "    raise RuntimeError('Found duplicate image names. Set ALLOW_RENAME_ON_CONFLICT=True or fix names.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "bf4360e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image-level counts (presence per image):\n",
            "  0: 712\n",
            "  1: 325\n",
            "  2: 289\n",
            "  BACKGROUND: 462\n",
            "Instance counts (rows in labels):\n",
            "  0: 712\n",
            "  1: 325\n",
            "  2: 290\n"
          ]
        }
      ],
      "source": [
        "def summarize_image_counts(samples):\n",
        "    image_counts = Counter()\n",
        "    instance_counts = Counter()\n",
        "    for s in samples:\n",
        "        if not s['labels']:\n",
        "            image_counts['BACKGROUND'] += 1\n",
        "        else:\n",
        "            for cls in s['labels']:\n",
        "                image_counts[cls] += 1\n",
        "        for cls, cnt in s['label_counts'].items():\n",
        "            instance_counts[cls] += cnt\n",
        "    return image_counts, instance_counts\n",
        "\n",
        "image_counts, instance_counts = summarize_image_counts(samples)\n",
        "print('Image-level counts (presence per image):')\n",
        "for k, v in sorted(image_counts.items(), key=lambda kv: str(kv[0])):\n",
        "    print(f'  {k}: {v}')\n",
        "print('Instance counts (rows in labels):')\n",
        "for k, v in sorted(instance_counts.items(), key=lambda kv: str(kv[0])):\n",
        "    print(f'  {k}: {v}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_primary(samples, val_ratio, seed):\n",
        "    groups = defaultdict(list)\n",
        "    for s in samples:\n",
        "        groups[s['primary']].append(s)\n",
        "    rng = random.Random(seed)\n",
        "    train, val = [], []\n",
        "    for _, items in groups.items():\n",
        "        rng.shuffle(items)\n",
        "        n_val = int(round(len(items) * val_ratio))\n",
        "        val.extend(items[:n_val])\n",
        "        train.extend(items[n_val:])\n",
        "    rng.shuffle(train)\n",
        "    rng.shuffle(val)\n",
        "    return train, val\n",
        "\n",
        "def split_multilabel_greedy(samples, val_ratio, seed):\n",
        "    rng = random.Random(seed)\n",
        "    labels = set()\n",
        "    total_counts = Counter()\n",
        "    for s in samples:\n",
        "        label_set = s['labels'] if s['labels'] else {'BACKGROUND'}\n",
        "        for lbl in label_set:\n",
        "            labels.add(lbl)\n",
        "            total_counts[lbl] += 1\n",
        "\n",
        "    labels = sorted(labels, key=lambda x: str(x))\n",
        "    target_val = {lbl: int(round(total_counts[lbl] * val_ratio)) for lbl in labels}\n",
        "    current_val = {lbl: 0 for lbl in labels}\n",
        "\n",
        "    label_to_indices = {lbl: set() for lbl in labels}\n",
        "    for idx, s in enumerate(samples):\n",
        "        label_set = s['labels'] if s['labels'] else {'BACKGROUND'}\n",
        "        for lbl in label_set:\n",
        "            label_to_indices[lbl].add(idx)\n",
        "\n",
        "    def need(lbl):\n",
        "        return target_val[lbl] - current_val[lbl]\n",
        "\n",
        "    def sample_score(idx):\n",
        "        label_set = samples[idx]['labels'] if samples[idx]['labels'] else {'BACKGROUND'}\n",
        "        return sum(max(need(lbl), 0) for lbl in label_set)\n",
        "\n",
        "    remaining = set(range(len(samples)))\n",
        "    val_set = set()\n",
        "\n",
        "    while remaining:\n",
        "        label = max(labels, key=lambda l: (need(l), -total_counts[l]))\n",
        "        if need(label) <= 0:\n",
        "            break\n",
        "        candidates = list(label_to_indices[label] & remaining)\n",
        "        if not candidates:\n",
        "            current_val[label] = target_val[label]\n",
        "            continue\n",
        "        best = max(candidates, key=lambda idx: (sample_score(idx), rng.random()))\n",
        "        val_set.add(best)\n",
        "        remaining.remove(best)\n",
        "        label_set = samples[best]['labels'] if samples[best]['labels'] else {'BACKGROUND'}\n",
        "        for lbl in label_set:\n",
        "            current_val[lbl] += 1\n",
        "\n",
        "    train_set = set(remaining)\n",
        "    target_val_size = int(round(len(samples) * val_ratio))\n",
        "    if len(val_set) < target_val_size:\n",
        "        needed = target_val_size - len(val_set)\n",
        "        candidates = list(train_set)\n",
        "        candidates.sort(key=sample_score, reverse=True)\n",
        "        for idx in candidates[:needed]:\n",
        "            train_set.remove(idx)\n",
        "            val_set.add(idx)\n",
        "    elif len(val_set) > target_val_size:\n",
        "        extra = len(val_set) - target_val_size\n",
        "        candidates = list(val_set)\n",
        "        candidates.sort(key=sample_score)\n",
        "        for idx in candidates[:extra]:\n",
        "            val_set.remove(idx)\n",
        "            train_set.add(idx)\n",
        "\n",
        "    train = [samples[i] for i in train_set]\n",
        "    val = [samples[i] for i in val_set]\n",
        "    rng.shuffle(train)\n",
        "    rng.shuffle(val)\n",
        "    return train, val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1431 | Val: 357\n"
          ]
        }
      ],
      "source": [
        "if SPLIT_STRATEGY == 'primary_label':\n",
        "    train_samples, val_samples = split_primary(samples, VAL_RATIO, SEED)\n",
        "elif SPLIT_STRATEGY == 'multilabel_greedy':\n",
        "    train_samples, val_samples = split_multilabel_greedy(samples, VAL_RATIO, SEED)\n",
        "else:\n",
        "    raise ValueError('Unknown SPLIT_STRATEGY')\n",
        "\n",
        "print(f'Train: {len(train_samples)} | Val: {len(val_samples)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train split\n",
            "  Image-level counts:\n",
            "    0: 570\n",
            "    1: 260\n",
            "    2: 231\n",
            "    BACKGROUND: 370\n",
            "  Instance counts:\n",
            "    0: 570\n",
            "    1: 260\n",
            "    2: 232\n",
            "Val split\n",
            "  Image-level counts:\n",
            "    0: 142\n",
            "    1: 65\n",
            "    2: 58\n",
            "    BACKGROUND: 92\n",
            "  Instance counts:\n",
            "    0: 142\n",
            "    1: 65\n",
            "    2: 58\n"
          ]
        }
      ],
      "source": [
        "def summarize_split(samples, title):\n",
        "    image_counts, instance_counts = summarize_image_counts(samples)\n",
        "    print(title)\n",
        "    print('  Image-level counts:')\n",
        "    for k, v in sorted(image_counts.items(), key=lambda kv: str(kv[0])):\n",
        "        print(f'    {k}: {v}')\n",
        "    print('  Instance counts:')\n",
        "    for k, v in sorted(instance_counts.items(), key=lambda kv: str(kv[0])):\n",
        "        print(f'    {k}: {v}')\n",
        "\n",
        "summarize_split(train_samples, 'Train split')\n",
        "summarize_split(val_samples, 'Val split')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9a6f5928",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imagens com >1 instancia da classe 2: 1\n",
            "2x | c:\\Users\\GainTech0014\\Documents\\yolov8_model\\data\\diurno\\images\\20260106095842.jpg | c:\\Users\\GainTech0014\\Documents\\yolov8_model\\data\\diurno\\labels\\20260106095842.txt\n"
          ]
        }
      ],
      "source": [
        "target_cls = 2\n",
        "multi = []\n",
        "\n",
        "for s in train_samples:\n",
        "    cnt = s[\"label_counts\"].get(target_cls, 0)\n",
        "    if cnt > 1:\n",
        "        multi.append((cnt, s[\"image_path\"], s[\"label_path\"]))\n",
        "\n",
        "print(f\"Imagens com >1 instancia da classe {target_cls}: {len(multi)}\")\n",
        "for cnt, img, lbl in sorted(multi, key=lambda x: x[0], reverse=True):\n",
        "    print(f\"{cnt}x | {img} | {lbl}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split written to: c:\\Users\\GainTech0014\\Documents\\yolov8_model\\dataset\\Diurnas_resplit_v1\n"
          ]
        }
      ],
      "source": [
        "def ensure_dirs(root: Path):\n",
        "    (root / 'train' / 'images').mkdir(parents=True, exist_ok=True)\n",
        "    (root / 'train' / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "    (root / 'valid' / 'images').mkdir(parents=True, exist_ok=True)\n",
        "    (root / 'valid' / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def get_output_name(sample):\n",
        "    if ALLOW_RENAME_ON_CONFLICT:\n",
        "        return make_unique_name(sample['image_path'])\n",
        "    return sample['image_path'].name\n",
        "\n",
        "def copy_or_move(src: Path, dst: Path, mode: str):\n",
        "    if mode == 'copy':\n",
        "        shutil.copy2(src, dst)\n",
        "    elif mode == 'move':\n",
        "        shutil.move(src, dst)\n",
        "    else:\n",
        "        raise ValueError('COPY_MODE must be copy or move')\n",
        "\n",
        "def write_split(samples, subset):\n",
        "    for s in samples:\n",
        "        out_name = get_output_name(s)\n",
        "        img_dst = OUTPUT_ROOT / subset / 'images' / out_name\n",
        "        lbl_dst = OUTPUT_ROOT / subset / 'labels' / f'{Path(out_name).stem}.txt'\n",
        "        if DRY_RUN:\n",
        "            continue\n",
        "        copy_or_move(s['image_path'], img_dst, COPY_MODE)\n",
        "        copy_or_move(s['label_path'], lbl_dst, COPY_MODE)\n",
        "\n",
        "if not DRY_RUN:\n",
        "    ensure_dirs(OUTPUT_ROOT)\n",
        "    write_split(train_samples, 'train')\n",
        "    write_split(val_samples, 'valid')\n",
        "    print('Split written to:', OUTPUT_ROOT)\n",
        "else:\n",
        "    print('DRY_RUN=True: no files written')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_data_yaml(output_root: Path, class_names):\n",
        "    if not class_names:\n",
        "        return\n",
        "    yaml_text = (\n",
        "        'train: train/images\\n'\n",
        "        'val: valid/images\\n\\n'\n",
        "        f'nc: {len(class_names)}\\n'\n",
        "        f'names: {class_names}\\n'\n",
        "    )\n",
        "    if DRY_RUN:\n",
        "        print('DRY_RUN=True: would write data.yaml with:')\n",
        "        print(yaml_text)\n",
        "        return\n",
        "    (output_root / 'data.yaml').write_text(yaml_text, encoding='utf-8')\n",
        "\n",
        "if WRITE_DATA_YAML:\n",
        "    write_data_yaml(OUTPUT_ROOT, CLASS_NAMES)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
